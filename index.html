<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Video Conference with Hand Tracking</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.0/socket.io.js"></script>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            height: 100%;
            width: 100%;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            background-color: #f0f0f0;
        }
        #video-container {
            display: flex;
            width: 100%;
            height: 100%;
            background-color: #ffffff;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        .video-wrapper {
            width: 50%;
            height: 100%;
            display: flex;
            justify-content: center;
            align-items: center;
            background-color: #f0f0f0;
            position: relative;
        }
        .video-wrapper::before {
            content: "";
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            font-size: 24px;
            color: #888888;
        }
        video {
            width: 100%;
            height: 100%;
            object-fit: contain;
            position: absolute;
            /* transform: scaleX(-1); */
        }
        #localVideo {
            transform: scaleX(-1);
        }
        #localVideo-wrapper::before {
            content: "Local Video";
        }
        #remoteVideo-wrapper::before {
            content: "Remote Video";
            object-fit: contain;
        }
        #outputCanvas {
            position: absolute;
            object-fit: contain;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 0;
            pointer-events: none;
            transform: scaleX(-1);
        }
        #downloadButton {
            position: fixed;
            bottom: 20px;
            left: 20px;
            z-index: 2;
        }
    </style>
</head>
<body>
    <div id="video-container">
        <div class="video-wrapper" id="localVideo-wrapper">
            <video id="localVideo" autoplay playsinline muted></video>
            <canvas id="outputCanvas"></canvas>
        </div>
        <div class="video-wrapper" id="remoteVideo-wrapper">
            <video id="remoteVideo" autoplay playsinline></video>
        </div>
    </div>
    <button id="downloadButton" onclick="downloadCSV()">Download CSV</button>
    <script>
        const localVideo = document.getElementById('localVideo');
        const remoteVideo = document.getElementById('remoteVideo');
        const canvasElement = document.getElementById('outputCanvas');
        const canvasCtx = canvasElement.getContext('2d');
        
        let localStream;
        let handMovements = []; // Array to store hand movement data
        const loggingInterval = 5000; // Time in ms between logs, changed from 500000 for demo

        const hands = new Hands({
            locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
        });

        hands.setOptions({
            maxNumHands: 4,
            modelComplexity: 1,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5
        });
        
        hands.onResults(onResults);
        
        function onResults(results) {
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);
            if (results.multiHandLandmarks) {
                for (const landmarks of results.multiHandLandmarks) {
                    drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, {color: 'lime', lineWidth: 4});
                    drawLandmarks(canvasCtx, landmarks, {color: 'red', radius: 5});
                }
            }
            canvasCtx.restore();
            requestAnimationFrame(predictHands); // Continuously request frames for prediction
        }
        
        function startVideo(videoElement) {
            navigator.mediaDevices.getUserMedia({ video: true })
                .then(stream => {
                    videoElement.srcObject = stream;
                    localStream = stream;
                    stream.getTracks().forEach(track => peerConnection.addTrack(track, stream));
                    videoElement.play();
                    videoElement.onloadedmetadata = () => {
                        canvasElement.width = videoElement.videoWidth;
                        canvasElement.height = videoElement.videoHeight;
                        predictHands();
                    };
                })
                .catch(error => {
                    console.error('Error opening video camera.', error);
                });
        }

        
        function predictHands() {
            hands.send({image: localVideo});
        }
        
        startVideo(localVideo);
        
        
        const socket = io();  // Automatically connect to the host that serves the page
        // const socket = io.connect('https://powerful-caverns-44451-c8d559731987.herokuapp.com');
        let peerConnection = new RTCPeerConnection({
            iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
        });

        // Listen for tracks added to the peer connection
        peerConnection.ontrack = (event) => {
            console.log('Remote track received');
            if (!remoteVideo.srcObject || remoteVideo.srcObject.id !== event.streams[0].id) {
                remoteVideo.srcObject = event.streams[0];
                console.log('Remote video source set');
            }
        };

        // Handle ICE candidates
        peerConnection.onicecandidate = event => {
            if (event.candidate) {
                // Send the ICE candidate to the other peer
                console.log('Sending ICE candidate');
                socket.emit('ice-candidate', { candidate: event.candidate });
            }
        };

        peerConnection.oniceconnectionstatechange = () => {
            console.log('ICE Connection State Change:', peerConnection.iceConnectionState);
        };


        // Existing socket event handlers and other code
        socket.on('offer', data => {
            console.log('Received offer');  
            peerConnection.setRemoteDescription(new RTCSessionDescription(data.offer))
                .then(() => peerConnection.createAnswer())
                .then(answer => {
                    console.log('Sending answer');
                    peerConnection.setLocalDescription(answer);
                    socket.emit('answer', { answer });
                })
                .catch(e => console.error('Error handling offer:', e));
        });


        socket.on('answer', data => {
            console.log('Received answer');
            peerConnection.setRemoteDescription(new RTCSessionDescription(data.answer))
                .then(() => console.log('Remote description set with answer'))
                .catch(e => console.error('Error setting remote description with answer', e));
        });


        socket.on('ice-candidate', data => {
            console.log('Receiving ICE candidate');
            if (data.candidate) {
                let candidate = new RTCIceCandidate(data.candidate);
                peerConnection.addIceCandidate(candidate)
                    .then(() => console.log('ICE Candidate Added'))
                    .catch(e => console.error('Error adding received ICE candidate', e));
            }
        });

        function startCall() {
            peerConnection.createOffer()
                .then(offer => {
                    peerConnection.setLocalDescription(offer);
                    socket.emit('offer', { offer });
                });
        }



        function downloadCSV() {
        const rows = [
            ["time", "handIndex", "landmarkIndex", "x", "y", "z"]
        ];
        handMovements.forEach(move => {
            move.landmarks.forEach((landmark, index) => {
                rows.push([move.time, move.handIndex, index, landmark.x, landmark.y, landmark.z]);
            });
        });

        let csvContent = "data:text/csv;charset=utf-8,";
        rows.forEach(rowArray => {
            let row = rowArray.join(",");
            csvContent += row + "\r\n";
        });

        var encodedUri = encodeURI(csvContent);
        var link = document.createElement("a");
        link.setAttribute("href", encodedUri);
        link.setAttribute("download", "hand_movements.csv");
        document.body.appendChild(link);
        link.click();
        document.body.removeChild(link);
    }

    // Additional logging or storing data points for the CSV file
    function logHandMovements(results) {
        if (results.multiHandLandmarks) {
            results.multiHandLandmarks.forEach((landmarks, index) => {
                handMovements.push({
                    time: Date.now(),
                    handIndex: index,
                    landmarks: landmarks.map(l => ({x: l.x * canvasElement.width, y: l.y * canvasElement.height, z: l.z}))
                });
            });
        }
    }

    hands.onResults((results) => {
        onResults(results);
        logHandMovements(results); // Log data after drawing
    });

        startCall();

</script>
</body>
</html>
