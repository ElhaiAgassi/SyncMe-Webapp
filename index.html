<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Video Conference with Hand Tracking</title>
    <!-- Load MediaPipe Hands library for hand tracking -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <!-- Load MediaPipe Camera Utils for camera input handling -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <!-- Load MediaPipe Drawing Utils for rendering hand landmarks -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <!-- Load Socket.IO client for real-time communication -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.0/socket.io.js"></script>
    <style>
        /* CSS to ensure full viewport coverage and remove margins/padding */
        body, html {
            margin: 0;
            padding: 0;
            height: 100%;
            width: 100%;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            background-color: #f0f0f0;
        }
        /* Container for both local and remote video elements */
        #video-container {
            display: flex;
            width: 100%;
            height: 100%;
            background-color: #ffffff;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        /* Styling for each video wrapper */
        .video-wrapper {
            width: 50%;
            height: 100%;
            display: flex;
            justify-content: center;
            align-items: center;
            background-color: #f0f0f0;
            position: relative;
        }
        /* Pseudo-element for displaying video labels */
        .video-wrapper::before {
            content: "";
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            font-size: 24px;
            color: #888888;
        }
        /* Styling for video elements */
        video {
            width: 100%;
            height: 100%;
            object-fit: contain;
            position: absolute;
            /* transform: scaleX(-1); */
        }
        /* Mirror the local video */
        #localVideo {
            transform: scaleX(-1);
        }
        /* Labels for local and remote video */
        #localVideo-wrapper::before {
            content: "Local Video";
        }
        #remoteVideo-wrapper::before {
            content: "Remote Video";
            object-fit: contain;
        }
        /* Styling for the canvas overlay (hand tracking visualization) */
        #outputCanvas {
            position: absolute;
            object-fit: contain;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 0;
            pointer-events: none;
            transform: scaleX(-1);
        }
        /* Positioning for the download button */
        #downloadButton {
            position: fixed;
            bottom: 20px;
            left: 20px;
            z-index: 2;
        }
    </style>
</head>
<body>
    <!-- Container for video elements -->
    <div id="video-container">
        <!-- Wrapper for local video and hand tracking canvas -->
        <div class="video-wrapper" id="localVideo-wrapper">
            <video id="localVideo" autoplay playsinline muted></video>
            <canvas id="outputCanvas"></canvas>
        </div>
        <!-- Wrapper for remote video -->
        <div class="video-wrapper" id="remoteVideo-wrapper">
            <video id="remoteVideo" autoplay playsinline></video>
        </div>
    </div>
    <!-- Button to trigger CSV download of hand movement data -->
    <button id="downloadButton" onclick="downloadCSV()">Download CSV</button>
    <script>
        // Get references to HTML elements
        const localVideo = document.getElementById('localVideo');
        const remoteVideo = document.getElementById('remoteVideo');
        const canvasElement = document.getElementById('outputCanvas');
        const canvasCtx = canvasElement.getContext('2d');
        
        let localStream;
        let handMovements = []; // Array to store hand movement data
        const loggingInterval = 5000; // Time in ms between logs, changed from 500000 for demo

        // Initialize MediaPipe Hands
        const hands = new Hands({
            locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
        });

        // Configure hand detection options
        hands.setOptions({
            maxNumHands: 4,
            modelComplexity: 1,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5
        });
        
        // Set the callback function for hand detection results
        hands.onResults(onResults);
        
        // Function to handle hand detection results
        function onResults(results) {
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);
            if (results.multiHandLandmarks) {
                for (const landmarks of results.multiHandLandmarks) {
                    // Draw hand connections
                    drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, {color: 'lime', lineWidth: 4});
                    // Draw hand landmarks
                    drawLandmarks(canvasCtx, landmarks, {color: 'red', radius: 5});
                }
            }
            canvasCtx.restore();
            requestAnimationFrame(predictHands); // Continuously request frames for prediction
        }
        
        // Function to start video stream
        function startVideo(videoElement) {
            console.log('Attempting to start video...');
            navigator.mediaDevices.getUserMedia({ video: true, audio: true })
                .then(stream => {
                    console.log('Local stream obtained');
                    videoElement.srcObject = stream;
                    localStream = stream;
                    stream.getTracks().forEach(track => {
                        console.log('Adding track to peer connection:', track.kind);
                        peerConnection.addTrack(track, stream);
                    });
                    videoElement.play();
                    videoElement.onloadedmetadata = () => {
                        console.log('Video metadata loaded');
                        canvasElement.width = videoElement.videoWidth;
                        canvasElement.height = videoElement.videoHeight;
                        predictHands();
                        startCall(); // Call startCall here after stream is ready
                    };
                })
                .catch(error => {
                    console.error('Error opening video camera:', error);
                });
        }
        
        // Function to start hand detection
        function predictHands() {
            hands.send({image: localVideo});
        }
        
        // Start the local video stream
        startVideo(localVideo);

        // const socket = io.connect('https://powerful-caverns-44451-c8d559731987.herokuapp.com');
        
        // Create RTCPeerConnection for WebRTC
        let peerConnection = new RTCPeerConnection({
            iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
        });

        // Listen for tracks added to the peer connection
        peerConnection.ontrack = (event) => {
            console.log('Received remote track', event.track.kind);
            if (!remoteVideo.srcObject) {
                remoteVideo.srcObject = new MediaStream();
            }
            remoteVideo.srcObject.addTrack(event.track);
        };

        // Handle ICE candidates
        peerConnection.onicecandidate = event => {
            if (event.candidate) {
                console.log('New ICE candidate', event.candidate);
                socket.emit('ice-candidate', { candidate: event.candidate });
            }
        };

        peerConnection.oniceconnectionstatechange = () => {
        console.log('ICE connection state:', peerConnection.iceConnectionState);
        };

        peerConnection.onsignalingstatechange = () => {
        console.log('Signaling state:', peerConnection.signalingState);
        };

        // Initialize Socket.IO connection
        const socket = io();  // Automatically connect to the host that serves the page
        socket.on('connect', () => {
            console.log('Socket.IO connected');
        });
        socket.on('disconnect', () => {
            console.log('Socket.IO disconnected');
        });

        // Handle incoming offer
        socket.on('offer', data => {
            console.log('Received offer'); 
            console.log('data: ', data)
            peerConnection.setRemoteDescription(new RTCSessionDescription(data.offer))
                .then(() => peerConnection.createAnswer())
                .then(answer => {
                    console.log('Sending answer');
                    peerConnection.setLocalDescription(answer);
                    socket.emit('answer', { answer });
                })
                .catch(e => console.error('Error handling offer:', e));
        });

        // Handle incoming answer
        socket.on('answer', data => {
            console.log('Received answer');
            peerConnection.setRemoteDescription(new RTCSessionDescription(data.answer))
                .then(() => console.log('Remote description set with answer'))
                .catch(e => console.error('Error setting remote description with answer', e));
        });

        // Handle incoming ICE candidates
        socket.on('ice-candidate', data => {
            console.log('Receiving ICE candidate');
            if (data.candidate) {
                let candidate = new RTCIceCandidate(data.candidate);
                peerConnection.addIceCandidate(candidate)
                    .then(() => console.log('ICE Candidate Added'))
                    .catch(e => console.error('Error adding received ICE candidate', e));
            }
        });

        // Function to initiate a call
        function startCall() {
            console.log('Starting call...');
            if (localStream) {
                peerConnection.createOffer()
                    .then(offer => {
                        console.log('Offer created');
                        return peerConnection.setLocalDescription(offer);
                    })
                    .then(() => {
                        console.log('Local description set, sending offer');
                        socket.emit('offer', { offer: peerConnection.localDescription });
                    })
                    .catch(e => console.error('Error in startCall:', e));
            } else {
                console.log('Waiting for local stream');
            }
        }


        // Function to download hand movement data as CSV
        function downloadCSV() {
        const rows = [
            ["time", "handIndex", "landmarkIndex", "x", "y", "z"]
        ];
        handMovements.forEach(move => {
            move.landmarks.forEach((landmark, index) => {
                rows.push([move.time, move.handIndex, index, landmark.x, landmark.y, landmark.z]);
            });
        });

        let csvContent = "data:text/csv;charset=utf-8,";
        rows.forEach(rowArray => {
            let row = rowArray.join(",");
            csvContent += row + "\r\n";
        });

        var encodedUri = encodeURI(csvContent);
        var link = document.createElement("a");
        link.setAttribute("href", encodedUri);
        link.setAttribute("download", "hand_movements.csv");
        document.body.appendChild(link);
        link.click();
        document.body.removeChild(link);
    }

    // Function to log hand movements
    function logHandMovements(results) {
        if (results.multiHandLandmarks) {
            results.multiHandLandmarks.forEach((landmarks, index) => {
                handMovements.push({
                    time: Date.now(),
                    handIndex: index,
                    landmarks: landmarks.map(l => ({x: l.x * canvasElement.width, y: l.y * canvasElement.height, z: l.z}))
                });
            });
        }
    }

    // Set up hand detection results handler
    hands.onResults((results) => {
        onResults(results);
        logHandMovements(results); // Log data after drawing
    });

    // // Start the call
    // startCall();

</script>
</body>
</html>